# mlx-rs

Rust bindings for [MLX](https://github.com/ml-explore/mlx), Apple's array framework for machine learning on Apple silicon.

## Overview

MLX is an array framework for machine learning research on Apple silicon. `mlx-rs` provides safe, idiomatic Rust bindings to MLX via the [mlx-c](https://github.com/ml-explore/mlx-c) C API.

### Features

- **Safe Rust API**: High-level, ergonomic interface with automatic memory management
- **Zero-cost abstractions**: Thin wrapper over mlx-c with minimal overhead
- **Type safety**: Strongly-typed arrays and operations
- **Lazy evaluation**: Leverage MLX's lazy computation model
- **Unified memory**: Arrays accessible from both CPU and GPU without copies

## Project Structure

This repository contains two crates:

- **`mlx-sys`**: Low-level FFI bindings to mlx-c (unsafe)
- **`mlx`**: High-level safe Rust API (recommended for users)

## ğŸ§ª Installation & Setup

**Note:** These instructions are for the `release` branch, which uses dynamic binding generation.

### Prerequisites

1. **macOS with Apple Silicon** (M1, M2, M3, or later)
2. **Xcode Command Line Tools**: `xcode-select --install`
3. **CMake**: `brew install cmake`

### Step 1: Build the MLX-C Engine

`mlx-rs` relies on the C-wrapper to interface with the C++ core. 

**Why a fork?** The official `mlx-c` passes `mlx_optional_int` structs by value, 
which causes an [ABI mismatch](docs/Rust_C_ABI_Mismatch_Quantization.md) when called 
from Rust on ARM64. Our fork adds thin C wrapper functions that accept plain `int` parameters. 

You must build this locally first:

```bash
# Clone the patched mlx-c (includes quantize wrapper functions)
git clone https://github.com/MisterEkole/mlx-c.git
cd mlx-c


# Build with CMake
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j
```

### Step 2: Setup mlx-rs

```bash
# Clone the repository and switch to the release branch
git clone -b release https://github.com/MisterEkole/mlx-rs.git
cd mlx-rs

# Set the critical environment variable (Replace with your actual path from Step 1)
export MLX_C_PATH=/path/to/your/mlx-c

# Run the pre-flight check script to verify libraries are found
chmod +x check_env.sh
./check_env.sh
```

**CRITICAL:** You must build the mlx-sys crate first. This triggers the build script to generate a fresh `bindings.rs` file tailored to your local machine.

```bash
# Build the sys crate to generate bindings.rs
cargo build -p mlx-sys
```

### Step 3: Run Examples

Once the environment is validated and bindings are generated, you can run the provided test cases:

```bash
# Test basic array operations
cargo run --example basic_ops

# Test a Convolutional Neural Network training loop
cargo run --example cnn
```

### Step 4: Run Mistral-7B Inference

Run a full Mistral-7B large language model locally on Apple Silicon:
```bash
# Install HuggingFace CLI (if not already)
pip install huggingface-hub

# Login to HuggingFace
huggingface-cli login

# Download Mistral-7B-v0.1 (~14GB)
huggingface-cli download mistralai/Mistral-7B-v0.1 \
    "model-00001-of-00003.safetensors" \
    "model-00002-of-00003.safetensors" \
    "model-00003-of-00003.safetensors" \
    "tokenizer.json" \
    "config.json" \
    --local-dir ./mistral-7b

# Generate text
cargo run --example mistral -- ./mistral-7b "What is Rust?"
```


## ğŸ“Š Benchmarks

We compared the performance of **mlx-rs**, **MLX Python**, and **PyTorch MPS** across various machine learning workloads. Because all three frameworks dispatch to the same underlying Apple Metal kernels, the primary performance differences come from the execution model and framework overhead.

[![Benchmark Results Overview](./benchmarks/bench_results/img1.png)](https://claude.site/public/artifacts/8f2a2466-0c6c-4edd-a44a-8c12a2c935a0)


### Key Findings

* **MLX Python is the overall winner:** It is particularly dominant on training and inferenceâ€”up to **4Ã— faster** than mlx-rs on small MLP training and **2.6Ã— faster** on CNN training. While Rust inherently has less overhead, MLX Python's `value_and_grad` and optimizer are likely batching operations much more efficiently into the compute graph before dispatching to Metal.
* **mlx-rs suffers from FFI overhead in training loops:** The Rustâ†’C FFI boundary adds per-operation latency that becomes highly visible on smaller models. However, on pure compute workloads (like large matrix multiplications and element-wise operations), all three frameworks are within **~5%** of each other since the heavy lifting is done by the exact same Metal kernels.
* **PyTorch MPS has the best large matmul kernels:** PyTorch scales slightly better on massive matrices (roughly **6% faster** at 4096Â²). However, it falls behind on small-batch training, where its eager execution model adds significant overhead compared to MLX's lazy evaluation.

### Future Optimizations

The primary optimization opportunity for `mlx-rs` is reducing the number of FFI calls per training step. We are actively exploring exposing a fused `value_and_grad` + optimizer step directly at the C level to eliminate the Rustâ†’C roundtrips during tight training loops.

## Development Status

**âš ï¸ Early Development**: This project is in early development. APIs may change. Advanced features are being added regularly.

**ğŸ“Š For detailed project development and API coverage status, see [API_COVERAGE.md](API_COVERAGE.md)**

## Contributing

Contributions are welcome! This project follows the same spirit as MLX - designed by ML researchers for ML researchers.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Your Rust Application              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  mlx crate (Safe Rust API)          â”‚
â”‚  - Array, Dtype types                â”‚
â”‚  - Memory management via Drop        â”‚
â”‚  - Error handling                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  mlx-sys (Raw FFI Bindings)         â”‚
â”‚  - Generated via bindgen             â”‚
â”‚  - Unsafe C function declarations    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  mlx-c (C API)                       â”‚
â”‚  - C wrapper around MLX C++          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MLX (C++ Core)                      â”‚
â”‚  - Metal shaders                     â”‚
â”‚  - Array operations                  â”‚
â”‚  - Neural network primitives         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Why Rust + MLX?

- **Safety**: Rust's ownership system prevents common bugs
- **Performance**: Zero-cost abstractions compile to efficient code
- **Ecosystem**: Integrate with Rust's rich crate ecosystem
- **Ergonomics**: Idiomatic Rust API following language conventions
- **Apple Silicon**: Native performance on M-series chips

## License

MIT License - see LICENSE file for details.

This project is not officially affiliated with Apple. MLX is created by Apple's machine learning research team.

## Resources

- [MLX Documentation](https://ml-explore.github.io/mlx/)
- [MLX GitHub](https://github.com/ml-explore/mlx)
- [MLX C GitHub](https://github.com/ml-explore/mlx-c)
- [MLX Swift](https://github.com/ml-explore/mlx-swift) (similar approach for Swift)

## Acknowledgments

- Apple ML Research team for creating MLX
- The mlx-c contributors for providing the C API bridge
- The Rust community for excellent FFI tooling
