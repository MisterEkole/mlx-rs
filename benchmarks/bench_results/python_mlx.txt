╔══════════════════════════════════════════════════╗
║          Python MLX Benchmark Suite              ║
║          Device: Apple Silicon GPU               ║
╚══════════════════════════════════════════════════╝

══ MATMUL THROUGHPUT ══
  matmul 256x256                              14.92 ms total |    0.298 ms/iter  (50 iters)
  matmul 512x512                              23.60 ms total |    0.472 ms/iter  (50 iters)
  matmul 1024x1024                            52.16 ms total |    1.043 ms/iter  (50 iters)
  matmul 2048x2048                           273.55 ms total |    5.471 ms/iter  (50 iters)
  matmul 4096x4096                          2206.05 ms total |   44.121 ms/iter  (50 iters)

══ ELEMENT-WISE OPS (1M elements) ══
  add                                         73.59 ms total |    0.368 ms/iter  (200 iters)
  multiply                                    70.78 ms total |    0.354 ms/iter  (200 iters)
  exp                                         59.01 ms total |    0.295 ms/iter  (200 iters)
  sin                                         59.10 ms total |    0.295 ms/iter  (200 iters)
  sqrt                                        73.05 ms total |    0.365 ms/iter  (200 iters)

══ MLP TRAINING STEP ══
  MLP fwd+bwd+update B=32 [128->256->256->10]    53.37 ms total |    0.534 ms/iter  (100 iters)
  MLP fwd+bwd+update B=64 [512->1024->1024->100]   269.97 ms total |    2.700 ms/iter  (100 iters)
  MLP fwd+bwd+update B=128 [784->2048->2048->10]   863.53 ms total |    8.635 ms/iter  (100 iters)

══ CNN TRAINING STEP (MNIST-like) ══
  CNN fwd+bwd+update B=32 [28x28x1 -> 10]     63.74 ms total |    0.637 ms/iter  (100 iters)

══ TRANSFORMER ENCODER FORWARD ══
  Encoder fwd B=16 S=32 d=64 h=4 L=2          33.08 ms total |    0.662 ms/iter  (50 iters)
  Encoder fwd B=16 S=64 d=128 h=4 L=4         98.84 ms total |    1.977 ms/iter  (50 iters)
  Encoder fwd B=8 S=128 d=256 h=8 L=6        318.40 ms total |    6.368 ms/iter  (50 iters)

══ DONE ══
